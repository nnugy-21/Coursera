## About this Module
Welcome to this course on TensorFlow Lite, an exciting technology that allows you to put your models directly and literally into people's hands. You'll start with a deep dive into the technology, and how it works, learning about how you can optimize your models for mobile use -- where battery power and processing power become an important factor. You'll then look at building applications on Android and iOS that use models, and you'll see how to use the TensorFlow Lite Interpreter in these environments. You'll wrap up the course with a look at embedded systems and microcontrollers, running your models on Raspberry Pi and SparkFun Edge boards. Don't worry if you don't have access to the hardware -- for the most part you'll be able to do everything in emulated environments. So, let's get started by looking at what TensorFlow is and how it works!

## Learning Objectives
* Understand how TensorFlow Lite works under the hood
* Describe how model quantization works
* Explain how GPU delegates work
* Explain the Optimization techniques available in TensorFlow Lite

## Resources
* [More depth about GPU delegates (youtube)](https://www.youtube.com/watch?v=QSbAUxWfxQw)
