## About this Module

Last week you saw how to improve the results from your deep neural network using convolutions. It was a good start, but the data you used was very basic. What happens when your images are larger, or if the features aren’t always in the same place? Andrew and Laurence discuss this to prepare you for what you’ll learn this week: handling complex images!

## Resources
* [How Tensorflow Solve Real-world Problem (youtube)](https://www.youtube.com/watch?v=NlpS-DhayQA)
* [Understanding Learning Rate (youtube)](https://youtu.be/zLRB4oupj6g)
* [Understanding Learning Rate (webpage)](https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/)
* [How to decide the number of hidden layers and neurons](https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e)
* [Understanding Loss Parameters](https://gombru.github.io/2018/05/23/cross_entropy_loss/)
* [Understanding Optimizer: RMSprop](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop)
